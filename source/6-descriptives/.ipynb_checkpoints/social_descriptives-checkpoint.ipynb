{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_africa_data():\n",
    "    africa = pd.read_excel('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Bolivia_Project/data/04-fakenews-Repository/06-virality/africa/social/0-prepare_data/facebook_africa.xlsx')[['clean_link', \n",
    "    'id_post', \n",
    "    'id_desinformacion', \n",
    "    'Verdict']].rename(columns = {'clean_link':'link_desinformacion'})\n",
    "    africa['link_post'] = africa.link_desinformacion\n",
    "    africa['label_desinformacion'] = africa['Verdict'].apply(lambda x: clean_label(x))\n",
    "    return(africa)\n",
    "\n",
    "def clean_label(x):\n",
    "    if x in ['Incorrect','Understated, exaggerated and incorrect',\n",
    "            'Seven incorrect, three correct, three unproven and one mostly correct']:\n",
    "        return('fake')\n",
    "    elif x in ['Mostly correct',\n",
    "               'A range of verdicts ranging from misleading to unproven and correct',\n",
    "              'Checked', 'Misleading']:\n",
    "        return('misleading')\n",
    "    else:\n",
    "        return('true')\n",
    "\n",
    "def load_panel():\n",
    "    social = pd.read_excel('/Users/cblanesg/misinformation_socialmedia/data/4-panel_data/social/panel_social.xlsx')\n",
    "    return(social)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_factchecks(panel):\n",
    "    panel = panel[['id_desinformacion', 'date_factcheck_final']].drop_duplicates()\n",
    "    panel['missing_factcheck'] = np.where(pd.isna(panel['date_factcheck_final']), 1, 0)\n",
    "    panel_counts = panel.groupby(['missing_factcheck']).count()\n",
    "    return(panel_counts)\n",
    "def clean_date_publication(x):\n",
    "    str_date = x.split(' ')[0]\n",
    "    return(datetime.date(int(x.split(' ')[0].split('-')[0]), \n",
    "                         int(x.split(' ')[0].split('-')[1]),\n",
    "                        int(x.split(' ')[0].split('-')[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries(panel):\n",
    "    ## data of factcheck\n",
    "    panel_fc = panel[['id_desinformacion', 'date_factcheck_final']].drop_duplicates()\n",
    "    panel_fc['factcheck'] = np.where(pd.isna(panel_fc['date_factcheck_final']), 0, 1)\n",
    "    panel_fc = panel_fc[['factcheck', 'id_desinformacion']]\n",
    "    \n",
    "    ## data of time series\n",
    "    #panel = panel[abs(panel['days_since_factcheck']) <= 15]\n",
    "    \n",
    "    panel = panel[['date_timestep', 'id_desinformacion']]\n",
    "    panel_counts = panel.groupby(['id_desinformacion']).count().reset_index()\n",
    "    \n",
    "    panel_counts['dummy_timeseries'] = np.where(panel_counts['date_timestep'] > 1, 1, 0)\n",
    "    panel_ts = panel_counts[['id_desinformacion', 'dummy_timeseries']]  \n",
    "\n",
    "    all_data = pd.merge(left = panel_fc, \n",
    "            right = panel_ts, \n",
    "            on = 'id_desinformacion', \n",
    "            how = 'left')\n",
    "    \n",
    "    counts = all_data.groupby(['dummy_timeseries', 'factcheck']).count()\n",
    "    \n",
    "    return(counts)\n",
    "\n",
    "\n",
    "def load_data_fact_checks():\n",
    "    fc = pd.read_json('../../data/1-factchecks/2-clean_factchecks/factchecks_data.json')\n",
    "    fc = fc[fc['type_factcheck'] == 'social_media']\n",
    "    fc\n",
    "    return(fc)\n",
    "\n",
    "def clean_label(x):\n",
    "    if x in ['Incorrect','Understated, exaggerated and incorrect',\n",
    "            'Seven incorrect, three correct, three unproven and one mostly correct']:\n",
    "        return('fake')\n",
    "    elif x in ['Mostly correct',\n",
    "               'A range of verdicts ranging from misleading to unproven and correct',\n",
    "              'Checked', 'Misleading']:\n",
    "        return('misleading')\n",
    "    else:\n",
    "        return('true')\n",
    "def load_africa_data():\n",
    "    africa = pd.read_excel('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Bolivia_Project/data/04-fakenews-Repository/06-virality/africa/social/0-prepare_data/facebook_africa.xlsx')[['clean_link', \n",
    "    'id_post', \n",
    "    'id_desinformacion', \n",
    "    'Verdict']].rename(columns = {'clean_link':'link_desinformacion'})\n",
    "    africa['link_post'] = africa.link_desinformacion\n",
    "    africa['label_desinformacion'] = africa['Verdict'].apply(lambda x: clean_label(x))\n",
    "    return(africa)\n",
    "def load_social_data():\n",
    "    social = pd.read_excel('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Bolivia_Project/data/04-fakenews-Repository/06-virality/social/2-id_data/virality_fake_posts.xlsx')\n",
    "\n",
    "    social_misinformation = social[['id_post', 'id_desinformacion', 'link_desinformacion', 'link_crowdtangle', \n",
    "       'label_desinformacion', 'id_chequeo']].rename(columns = {'link_crowdtangle':'link_post', \n",
    "                                                               'id_chequeo':'id_factcheck'})\n",
    "    \n",
    "    return(social_misinformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_json('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Bolivia_Project/data/04-fakenews-Repository/06-virality/social/3-panel_disaggreagted/panel_facebook_posts.json')\n",
    "\n",
    "factchecks_id = load_social_data()[['id_desinformacion', 'id_factcheck']].dropna().drop_duplicates()\n",
    "factchecks = load_data_fact_checks()\n",
    "\n",
    "complete_fc = pd.merge(left = factchecks, \n",
    "        right = factchecks_id, \n",
    "        on = 'id_factcheck', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['date_publication'] = data['date_post'].apply(lambda x: clean_date_publication(x))\n",
    "data['date_timestep'] = data['Score Date (GMT)'].apply(lambda x: clean_date_publication(x))\n",
    "data['days_since_publication'] = data.apply(lambda x: (x['date_timestep'] - x['date_publication']).days, axis = 1)\n",
    "\n",
    "social = pd.merge(left = data, \n",
    "        right = complete_fc, \n",
    "        on = 'id_desinformacion', \n",
    "        how = 'left')\n",
    "#social = social[~social['date_factcheck_final'].isna()]\n",
    "#social['date_factcheck'] = social['date_factcheck_final'].apply(lambda x: datetime.date(int(x.split('-')[0]), \n",
    " #                                                                              int(x.split('-')[1]), \n",
    " #                                                                              int(x.split('-')[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_desinformacion</th>\n",
       "      <th>date_factcheck_final</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_factcheck</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>308</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id_desinformacion  date_factcheck_final\n",
       "missing_factcheck                                         \n",
       "0                                308                   308\n",
       "1                                 17                     0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_factchecks(social)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pct of posts with no factcheck:  36.57817109144543 \n",
      "Pct of posts with factcheck:  63.421828908554566\n"
     ]
    }
   ],
   "source": [
    "print('Pct of posts with no factcheck: ', 124/(124 + 215)*100, \n",
    "      '\\nPct of posts with factcheck: ',215/(124 + 215)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id_desinformacion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummy_timeseries</th>\n",
       "      <th>factcheck</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id_desinformacion\n",
       "dummy_timeseries factcheck                   \n",
       "0                0                         10\n",
       "                 1                        185\n",
       "1                0                          7\n",
       "                 1                        123"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries(social)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "    panel_fc = social[['id_desinformacion', 'date_factcheck_final', 'id_factcheck']].drop_duplicates()\n",
    "    panel_fc['factcheck'] = np.where(pd.isna(panel_fc['date_factcheck_final']), 0, 1)\n",
    "    panel_fc = panel_fc[['factcheck', 'id_desinformacion', 'id_factcheck']]\n",
    "    \n",
    "    panel = social[['date_timestep', 'id_desinformacion']]\n",
    "    panel_counts = panel.groupby(['id_desinformacion']).count().reset_index()\n",
    "    \n",
    "    panel_counts['dummy_timeseries'] = np.where(panel_counts['date_timestep'] > 1, 1, 0)\n",
    "    panel_ts = panel_counts[['id_desinformacion', 'dummy_timeseries']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "factchecks = social[['id_factcheck', 'id_desinformacion']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.merge(left = panel_ts, \n",
    "        right =factchecks, \n",
    "        on = 'id_desinformacion', \n",
    "        how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[all_data['dummy_timeseries'] == 1].to_excel('../../data/1-factchecks/2-clean_factchecks/factchecks_subset_social.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_ts[panel_ts['dummy_timeseries'] == 1].to_excel('../../data/1-factchecks/2-clean_factchecks/factchecks_subset_social.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pct of posts with timeseries data:  39.233038348082594 \n",
      "Pct of posts with factcheck:  60.766961651917406\n"
     ]
    }
   ],
   "source": [
    "print('Pct of posts with timeseries data: ', 133/(133 + 206)*100, \n",
    "      '\\nPct of posts with factcheck: ',206/(133 + 206)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
