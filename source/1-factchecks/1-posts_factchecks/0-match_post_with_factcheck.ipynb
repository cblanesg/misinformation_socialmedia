{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import numpy as np\n",
    "import re\n",
    "from os import listdir\n",
    "from tqdm import tqdm\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_date_partnership(organizacion):\n",
    "    dict_poynters = {'africa_check':datetime.date(2019, 8, 15), \n",
    "                    'la_silla_vacia':datetime.date(2020, 1, 31),\n",
    "                     'chequeado':datetime.date(2018, 5, 1),\n",
    "                     'animalpolitico':datetime.date(2018, 3, 1),\n",
    "                     'colombiacheck': datetime.date(2020, 9, 28),\n",
    "                     'ecuador_chequea':datetime.date(2020, 4, 1),\n",
    "                     'larepublica':datetime.date(2020, 6, 1),\n",
    "                    }\n",
    "    \n",
    "    if organizacion in dict_poynters.keys():\n",
    "        return(dict_poynters[organizacion])\n",
    "    else:\n",
    "        return(np.nan)\n",
    "\n",
    "def poynter_any_time(organizacion):\n",
    "    dict_poynters = {'africa_check':datetime.date(2019, 8, 15), \n",
    "                    'la_silla_vacia':datetime.date(2020, 1, 31),\n",
    "                     'chequeado':datetime.date(2018, 5, 1),\n",
    "                     'animalpolitico':datetime.date(2018, 3, 1),\n",
    "                     'colombiacheck': datetime.date(2020, 9, 28),\n",
    "                     'ecuador_chequea':datetime.date(2020, 4, 1),\n",
    "                     'larepublica':datetime.date(2020, 6, 1),\n",
    "                    }\n",
    "    \n",
    "    if organizacion in dict_poynters.keys():\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)\n",
    "    \n",
    "    \n",
    "def title_factcheck_function(x):\n",
    "    if pd.isna(x):\n",
    "        return(None)\n",
    "    else:\n",
    "        return(re.sub('[/]$', '', x).split('/')[-1:][0])\n",
    "\n",
    "def clean_links(df):\n",
    "    final_links = []\n",
    "    for i in list(df['Final Link']):\n",
    "        if pd.isna(i):\n",
    "            final_links.append(np.nan)\n",
    "        elif any(re.findall('https://www.facebook.com/login/|https://api.whatsapp.com/',i)):\n",
    "            final_links.append(np.nan)\n",
    "        else:\n",
    "            final_links.append(i)\n",
    "    df['Final Link'] = final_links\n",
    "    df = df[~df['Final Link'].isna()]\n",
    "    df = df[df['Final Link'] != 'https://lasillavacia.com/']\n",
    "    return(df)\n",
    "\n",
    "def match_factcheck_w_posts(df, df_posts):\n",
    "    date_factchecks = []\n",
    "    match_link = []\n",
    "    score_match_link = []\n",
    "    match_title = []\n",
    "    score_match_title = []\n",
    "    post_url = []\n",
    "    \n",
    "    df = df.reset_index().drop('index', axis = 1)\n",
    "    df['title_factcheck'] = df.apply(lambda x: title_factcheck_function(x['link_chequeo']), axis = 1)\n",
    "    df_posts['title_link'] = df_posts.apply(lambda x: title_factcheck_function(x['Final Link']), axis = 1)\n",
    "    for i in tqdm(range(0, len(df))):\n",
    "        if pd.isna(df.loc[i]['date_factcheck_facebook']):\n",
    "            link_factcheck = df.loc[i]['link_chequeo']\n",
    "            \n",
    "            if pd.isna(link_factcheck):\n",
    "                    score_match_link.append(None)\n",
    "                    match_link.append(None)\n",
    "                    date_factchecks.append(None)\n",
    "                    match_title.append(None)\n",
    "                    score_match_title.append(None)\n",
    "                    post_url.append(None)\n",
    "            else:\n",
    "                match, score = process.extractOne(link_factcheck, list(df_posts['Final Link']))\n",
    "                if score >= 90:\n",
    "                    score_match_link.append(score)\n",
    "                    match_link.append(match)\n",
    "                    date_factchecks.append(list(df_posts[df_posts['Final Link'] == match].Created)[0])\n",
    "                    match_title.append(None)\n",
    "                    score_match_title.append(None)\n",
    "                    post_url.append(list(df_posts[df_posts['Final Link'] == match].URL)[0])\n",
    "                else:\n",
    "                    title_factcheck = df.loc[i]['title_factcheck']\n",
    "                    match, score = process.extractOne(title_factcheck, list(df_posts['title_link']))\n",
    "                    if score > 80:\n",
    "                        score_match_link.append(None)\n",
    "                        match_link.append(None)\n",
    "                        date_factchecks.append(list(df_posts[df_posts['title_link'] == match].Created)[0])\n",
    "                        match_title.append(match)\n",
    "                        score_match_title.append(score)\n",
    "                        post_url.append(list(df_posts[df_posts['title_link'] == match].URL)[0])\n",
    "                    else:\n",
    "                        score_match_link.append(None)\n",
    "                        match_link.append(None)\n",
    "                        date_factchecks.append(None)\n",
    "                        match_title.append(None)\n",
    "                        score_match_title.append(None)\n",
    "                        post_url.append(None)\n",
    "        else:\n",
    "            score_match_link.append(None)\n",
    "            match_link.append(None)\n",
    "            date_factchecks.append(df.loc[i]['date_factcheck_facebook'])\n",
    "            match_title.append(None)\n",
    "            score_match_title.append(None)\n",
    "            post_url.append(None)\n",
    "            \n",
    "    df['date_factcheck_facebook'] = date_factchecks\n",
    "    df['match_link_factcheck'] = match_link\n",
    "    df['score_match_link_factcheck'] = score_match_link\n",
    "    df['match_title_factcheck'] = match_title\n",
    "    df['score_match_title_factcheck'] = score_match_title\n",
    "    df['post_url'] = post_url\n",
    "    return(df)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n"
     ]
    }
   ],
   "source": [
    "dates_chequeos = pd.read_json('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Bolivia_Project/data/04-fakenews-Repository/06-virality/newspapers/2-id_data/dates_verificaciones.json')\n",
    "id_data = pd.read_excel('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Bolivia_Project/data/04-fakenews-Repository/06-virality/newspapers/2-id_data/virality_id_newspapers.xlsx')\n",
    "\n",
    "data_factchecks = id_data[['label_desinformacion', 'id_chequeo', 'organizacion', \n",
    "        'link_chequeo', 'fecha_chequeo', 'id_desinformacion']]\n",
    "data_factchecks = data_factchecks.drop_duplicates()\n",
    "data_factchecks['date_factcheck_facebook'] = None\n",
    "\n",
    "posts_facebook = []\n",
    "path = '/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Bolivia_Project/data/04-fakenews-Repository/06-virality/factcheckers/posts_facebook/'\n",
    "for i in listdir(path):\n",
    "    try:\n",
    "        df = pd.read_csv(path + i)\n",
    "        df['organizacion'] = re.sub('[.]csv','', i)\n",
    "        posts_facebook.append(df)\n",
    "    except:\n",
    "        print(i)\n",
    "        \n",
    "posts_facebook = pd.concat(posts_facebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_data = []\n",
    "\n",
    "for i in tqdm(list(data_factchecks.organizacion.unique())[2:][7:]):\n",
    "    if i == 'Chequeado-LATAM':\n",
    "        df = data_factchecks[data_factchecks['organizacion'] == 'Chequeado-LATAM']\n",
    "        df_posts = posts_facebook[posts_facebook['organizacion'] == 'chequeado']\n",
    "        df_posts = clean_links(df_posts)\n",
    "        input_matches = df_posts[['Final Link', 'URL', 'Created']].dropna()\n",
    "        out = match_factcheck_w_posts(df, input_matches)\n",
    "        matches_data.append(out)\n",
    "    else:        \n",
    "        df = data_factchecks[data_factchecks['organizacion'] == i]\n",
    "        df_posts = posts_facebook[posts_facebook['organizacion'] == i]     \n",
    "        df_posts = clean_links(df_posts)\n",
    "        input_matches = df_posts[['Final Link', 'URL', 'Created']].dropna()\n",
    "        out = match_factcheck_w_posts(df, input_matches)\n",
    "        matches_data.append(out)\n",
    "\n",
    "df_out = pd.concat(matches_data)\n",
    "\n",
    "df_out.to_excel('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Bolivia_Project/data/04-fakenews-Repository/06-virality/newspapers/2-id_data/data_to_check.xlsx')\n",
    "\n",
    "df_out = df_out[df_out['organizacion'] != 'la_silla_vacia']\n",
    "\n",
    "        df = data_factchecks[data_factchecks['organizacion'] == 'la_silla_vacia']\n",
    "        df_posts = posts_facebook[posts_facebook['organizacion'] == 'la_silla_vacia']\n",
    "        df_posts = clean_links(df_posts)\n",
    "        input_matches = df_posts[['Final Link', 'URL', 'Created']].dropna()\n",
    "        out = match_factcheck_w_posts(df, input_matches)\n",
    "        \n",
    "\n",
    "df_clean = pd.concat([df_out, out])\n",
    "\n",
    "data_ids = data_factchecks[['id_chequeo', 'id_desinformacion']].drop_duplicates().set_index('id_chequeo')['id_desinformacion'].to_dict()\n",
    "\n",
    "df_clean = df_clean[df_clean['label_desinformacion'] == 'fake']\n",
    "df_clean['id_desinformacion'] = df_clean['id_chequeo'].apply(lambda x: data_ids[x])\n",
    "df_out_factchecks = df_clean[['organizacion','id_chequeo', 'fecha_chequeo', 'post_url','label_desinformacion', 'id_desinformacion',\n",
    "       'date_factcheck_facebook', 'link_chequeo','match_link_factcheck', 'score_match_link_factcheck', \n",
    "       'title_factcheck','match_title_factcheck', 'score_match_title_factcheck','label_desinformacion']].rename(columns = {'link_chequeo':'link_factcheck', \n",
    "                                                                                                                          'organizacion':'factchecker', \n",
    "                                                                                                                          'fecha_chequeo':'date_factcheck',\n",
    "                                                                                                                          'id_chequeo':'id_factcheck', \n",
    "                                                                                                                          'post_url':'post_factcheck'})\n",
    "\n",
    "\n",
    "\n",
    "df_out_factchecks['poynter_facebook'] = df_out_factchecks.apply(lambda x: poynter_any_time(x['factchecker']), axis = 1)\n",
    "df_out_factchecks['date_partnership_facebook'] = df_out_factchecks.apply(lambda x: assign_date_partnership(x['factchecker']), axis = 1)\n",
    "\n",
    "df_out_factchecks['no_factcheck'] = np.where(pd.isna(df_out_factchecks['id_factcheck']), 1, 0)\n",
    "\n",
    "df_out_factchecks['no_socialmedia_factcheck'] = None\n",
    "df_out_factchecks['date_factcheck_twitter'] = None\n",
    "\n",
    "factchekers = df_out_factchecks[['factchecker',\n",
    "                                 'id_desinformacion', \n",
    "                                 'post_factcheck',\n",
    "              'id_factcheck', \n",
    "              'date_factcheck',\n",
    "              'date_factcheck_facebook', \n",
    "              'date_factcheck_twitter', \n",
    "              'label_desinformacion', \n",
    "              'no_factcheck',\n",
    "              'no_socialmedia_factcheck', \n",
    "                  'link_factcheck',\n",
    "            'match_link_factcheck', 'score_match_link_factcheck', \n",
    "       'title_factcheck','match_title_factcheck', 'score_match_title_factcheck']]\n",
    "\n",
    "factchekers.to_excel('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Bolivia_Project/data/04-fakenews-Repository/06-virality/newspapers/2-id_data/factchekers_check2.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
